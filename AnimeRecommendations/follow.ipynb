{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/YiHsien/Documents/kaggle/AnimeRecommendations\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anime = pd.read_csv('anime.csv')\n",
    "rating = pd.read_csv('rating.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>rating_x</th>\n",
       "      <th>name</th>\n",
       "      <th>genre</th>\n",
       "      <th>type</th>\n",
       "      <th>episodes</th>\n",
       "      <th>rating_y</th>\n",
       "      <th>members</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98741</th>\n",
       "      <td>1</td>\n",
       "      <td>442</td>\n",
       "      <td>-1</td>\n",
       "      <td>Naruto Movie 1: Dai Katsugeki!! Yuki Hime Shin...</td>\n",
       "      <td>Adventure, Comedy, Drama, Historical, Shounen,...</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1</td>\n",
       "      <td>7.17</td>\n",
       "      <td>120571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98742</th>\n",
       "      <td>5</td>\n",
       "      <td>442</td>\n",
       "      <td>4</td>\n",
       "      <td>Naruto Movie 1: Dai Katsugeki!! Yuki Hime Shin...</td>\n",
       "      <td>Adventure, Comedy, Drama, Historical, Shounen,...</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1</td>\n",
       "      <td>7.17</td>\n",
       "      <td>120571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98743</th>\n",
       "      <td>54</td>\n",
       "      <td>442</td>\n",
       "      <td>-1</td>\n",
       "      <td>Naruto Movie 1: Dai Katsugeki!! Yuki Hime Shin...</td>\n",
       "      <td>Adventure, Comedy, Drama, Historical, Shounen,...</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1</td>\n",
       "      <td>7.17</td>\n",
       "      <td>120571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98744</th>\n",
       "      <td>99</td>\n",
       "      <td>442</td>\n",
       "      <td>2</td>\n",
       "      <td>Naruto Movie 1: Dai Katsugeki!! Yuki Hime Shin...</td>\n",
       "      <td>Adventure, Comedy, Drama, Historical, Shounen,...</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1</td>\n",
       "      <td>7.17</td>\n",
       "      <td>120571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98745</th>\n",
       "      <td>128</td>\n",
       "      <td>442</td>\n",
       "      <td>7</td>\n",
       "      <td>Naruto Movie 1: Dai Katsugeki!! Yuki Hime Shin...</td>\n",
       "      <td>Adventure, Comedy, Drama, Historical, Shounen,...</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1</td>\n",
       "      <td>7.17</td>\n",
       "      <td>120571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98746</th>\n",
       "      <td>129</td>\n",
       "      <td>442</td>\n",
       "      <td>8</td>\n",
       "      <td>Naruto Movie 1: Dai Katsugeki!! Yuki Hime Shin...</td>\n",
       "      <td>Adventure, Comedy, Drama, Historical, Shounen,...</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1</td>\n",
       "      <td>7.17</td>\n",
       "      <td>120571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98747</th>\n",
       "      <td>171</td>\n",
       "      <td>442</td>\n",
       "      <td>10</td>\n",
       "      <td>Naruto Movie 1: Dai Katsugeki!! Yuki Hime Shin...</td>\n",
       "      <td>Adventure, Comedy, Drama, Historical, Shounen,...</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1</td>\n",
       "      <td>7.17</td>\n",
       "      <td>120571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98748</th>\n",
       "      <td>188</td>\n",
       "      <td>442</td>\n",
       "      <td>-1</td>\n",
       "      <td>Naruto Movie 1: Dai Katsugeki!! Yuki Hime Shin...</td>\n",
       "      <td>Adventure, Comedy, Drama, Historical, Shounen,...</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1</td>\n",
       "      <td>7.17</td>\n",
       "      <td>120571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98749</th>\n",
       "      <td>190</td>\n",
       "      <td>442</td>\n",
       "      <td>5</td>\n",
       "      <td>Naruto Movie 1: Dai Katsugeki!! Yuki Hime Shin...</td>\n",
       "      <td>Adventure, Comedy, Drama, Historical, Shounen,...</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1</td>\n",
       "      <td>7.17</td>\n",
       "      <td>120571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98750</th>\n",
       "      <td>201</td>\n",
       "      <td>442</td>\n",
       "      <td>10</td>\n",
       "      <td>Naruto Movie 1: Dai Katsugeki!! Yuki Hime Shin...</td>\n",
       "      <td>Adventure, Comedy, Drama, Historical, Shounen,...</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1</td>\n",
       "      <td>7.17</td>\n",
       "      <td>120571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  anime_id  rating_x  \\\n",
       "98741        1       442        -1   \n",
       "98742        5       442         4   \n",
       "98743       54       442        -1   \n",
       "98744       99       442         2   \n",
       "98745      128       442         7   \n",
       "98746      129       442         8   \n",
       "98747      171       442        10   \n",
       "98748      188       442        -1   \n",
       "98749      190       442         5   \n",
       "98750      201       442        10   \n",
       "\n",
       "                                                    name  \\\n",
       "98741  Naruto Movie 1: Dai Katsugeki!! Yuki Hime Shin...   \n",
       "98742  Naruto Movie 1: Dai Katsugeki!! Yuki Hime Shin...   \n",
       "98743  Naruto Movie 1: Dai Katsugeki!! Yuki Hime Shin...   \n",
       "98744  Naruto Movie 1: Dai Katsugeki!! Yuki Hime Shin...   \n",
       "98745  Naruto Movie 1: Dai Katsugeki!! Yuki Hime Shin...   \n",
       "98746  Naruto Movie 1: Dai Katsugeki!! Yuki Hime Shin...   \n",
       "98747  Naruto Movie 1: Dai Katsugeki!! Yuki Hime Shin...   \n",
       "98748  Naruto Movie 1: Dai Katsugeki!! Yuki Hime Shin...   \n",
       "98749  Naruto Movie 1: Dai Katsugeki!! Yuki Hime Shin...   \n",
       "98750  Naruto Movie 1: Dai Katsugeki!! Yuki Hime Shin...   \n",
       "\n",
       "                                                   genre   type episodes  \\\n",
       "98741  Adventure, Comedy, Drama, Historical, Shounen,...  Movie        1   \n",
       "98742  Adventure, Comedy, Drama, Historical, Shounen,...  Movie        1   \n",
       "98743  Adventure, Comedy, Drama, Historical, Shounen,...  Movie        1   \n",
       "98744  Adventure, Comedy, Drama, Historical, Shounen,...  Movie        1   \n",
       "98745  Adventure, Comedy, Drama, Historical, Shounen,...  Movie        1   \n",
       "98746  Adventure, Comedy, Drama, Historical, Shounen,...  Movie        1   \n",
       "98747  Adventure, Comedy, Drama, Historical, Shounen,...  Movie        1   \n",
       "98748  Adventure, Comedy, Drama, Historical, Shounen,...  Movie        1   \n",
       "98749  Adventure, Comedy, Drama, Historical, Shounen,...  Movie        1   \n",
       "98750  Adventure, Comedy, Drama, Historical, Shounen,...  Movie        1   \n",
       "\n",
       "       rating_y  members  \n",
       "98741      7.17   120571  \n",
       "98742      7.17   120571  \n",
       "98743      7.17   120571  \n",
       "98744      7.17   120571  \n",
       "98745      7.17   120571  \n",
       "98746      7.17   120571  \n",
       "98747      7.17   120571  \n",
       "98748      7.17   120571  \n",
       "98749      7.17   120571  \n",
       "98750      7.17   120571  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergedata = pd.merge(rating,anime,on=['anime_id','anime_id'])\n",
    "mergedata = mergedata[mergedata['type']=='Movie']\n",
    "mergedata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(736398, 9) (315600, 9)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(mergedata, test_size=0.3)\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 將電影類別換成數字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class CounterEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"依照出現頻率進行編碼, 頻率由高到低的index = 0, 1, 2, 3 ..., 以此類推\"\"\"\n",
    "    def fit(self, y):\n",
    "        counter = pd.Series(y).value_counts()\n",
    "        self.enc = dict(zip([None] + counter.index.tolist(), range(len(counter) + 1)))\n",
    "        self.invEnc = dict(zip(self.enc.values(), self.enc.keys()))\n",
    "        self.classes_ = counter.index.values\n",
    "        return self\n",
    "\n",
    "    def transform(self, y):\n",
    "        return pd.Series(y).map(self.enc).fillna(0).values\n",
    "\n",
    "    def fit_transform(self, y, **fit_params):\n",
    "        return self.fit(y).transform(y)\n",
    "    \n",
    "    def inverse_transform(self, y):\n",
    "        return pd.Series(y).map(self.invEnc).values\n",
    "\n",
    "\n",
    "class OrderedMapper(CounterEncoder):\n",
    "    def fit(self, y):\n",
    "        uniq = pd.Series(y).unique()\n",
    "        self.enc = dict(zip(uniq, range(len(uniq))))\n",
    "        self.invEnc = dict(zip(range(len(uniq)), uniq))\n",
    "        self.classes_ = uniq\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter, OrderedDict\n",
    "def doMovies(movies):\n",
    "    \"\"\"處理 movie: genres 轉換成數字\"\"\"\n",
    "    movies = movies.reset_index(drop=True)\n",
    "    movies.loc[movies.genre == \"(no genres listed)\", \"genre\"] = \"\"\n",
    "    movies['genre']=movies['genre'].fillna('')\n",
    "    movies[\"genre\"] = movies.genre.str.split(\",\")\n",
    "    genreMap = Counter()\n",
    "    movies.genre.map(genreMap.update)\n",
    "    om = OrderedMapper().fit([e[0] for e in genreMap.most_common()])\n",
    "    movies[\"genre\"] = movies.genre.map(lambda lst: [om.enc[e] for e in lst])\n",
    "    return movies, om"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_trans, genres_enc = doMovies(anime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_genres = len(genres_enc.enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/YiHsien/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>name</th>\n",
       "      <th>genre</th>\n",
       "      <th>type</th>\n",
       "      <th>episodes</th>\n",
       "      <th>rating</th>\n",
       "      <th>members</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32281</td>\n",
       "      <td>Kimi no Na wa.</td>\n",
       "      <td>[13, 7, 9, 12]</td>\n",
       "      <td>Movie</td>\n",
       "      <td>1</td>\n",
       "      <td>9.37</td>\n",
       "      <td>0.197872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5114</td>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>[1, 15, 11, 3, 17, 27, 4]</td>\n",
       "      <td>TV</td>\n",
       "      <td>64</td>\n",
       "      <td>9.26</td>\n",
       "      <td>0.782770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28977</td>\n",
       "      <td>Gintama°</td>\n",
       "      <td>[1, 6, 18, 30, 41, 2, 4]</td>\n",
       "      <td>TV</td>\n",
       "      <td>51</td>\n",
       "      <td>9.25</td>\n",
       "      <td>0.112689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9253</td>\n",
       "      <td>Steins;Gate</td>\n",
       "      <td>[49, 47]</td>\n",
       "      <td>TV</td>\n",
       "      <td>24</td>\n",
       "      <td>9.17</td>\n",
       "      <td>0.664325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9969</td>\n",
       "      <td>Gintama&amp;#039;</td>\n",
       "      <td>[1, 6, 18, 30, 41, 2, 4]</td>\n",
       "      <td>TV</td>\n",
       "      <td>51</td>\n",
       "      <td>9.16</td>\n",
       "      <td>0.149186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anime_id                              name                      genre  \\\n",
       "0     32281                    Kimi no Na wa.             [13, 7, 9, 12]   \n",
       "1      5114  Fullmetal Alchemist: Brotherhood  [1, 15, 11, 3, 17, 27, 4]   \n",
       "2     28977                          Gintama°   [1, 6, 18, 30, 41, 2, 4]   \n",
       "3      9253                       Steins;Gate                   [49, 47]   \n",
       "4      9969                     Gintama&#039;   [1, 6, 18, 30, 41, 2, 4]   \n",
       "\n",
       "    type episodes  rating   members  \n",
       "0  Movie        1    9.37  0.197872  \n",
       "1     TV       64    9.26  0.782770  \n",
       "2     TV       51    9.25  0.112689  \n",
       "3     TV       24    9.17  0.664325  \n",
       "4     TV       51    9.16  0.149186  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "movie_trans[\"members\"] = minmax_scale(movie_trans.members.fillna(movie_trans.members.median()))\n",
    "movie_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## leave on out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(589529, 9) (252624, 9)\n"
     ]
    }
   ],
   "source": [
    "#拿掉無評分的資料\n",
    "train = train[train['rating_x']!=-1]\n",
    "test = test[test['rating_x']!=-1]\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u = pd.DataFrame()\n",
    "u['user_id'] = mergedata['user_id'].unique()\n",
    "u['user'] = range(0,len(mergedata['user_id'].unique()))\n",
    "m = pd.DataFrame()\n",
    "m['anime_id'] = mergedata['anime_id'].unique()\n",
    "m['movie'] = range(0,len(mergedata['anime_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train,u,on=['user_id'])\n",
    "train = pd.merge(train,m,on=['anime_id'])\n",
    "test = pd.merge(test,u,on=['user_id'])\n",
    "test = pd.merge(test,m,on=['anime_id'])\n",
    "train.drop(['user_id','anime_id'], axis=1, inplace=True)\n",
    "test.drop(['user_id','anime_id'], axis=1, inplace=True)\n",
    "train.rename(columns={'user':'user_id','movie':'anime_id'}, inplace=True)\n",
    "test.rename(columns={'user':'user_id','movie':'anime_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_trans = pd.merge(movie_trans,m,on=['anime_id'])\n",
    "movie_trans.drop(['anime_id'], axis=1, inplace=True)\n",
    "movie_trans.rename(columns={'movie':'anime_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loo_preprocess(data, movie_trans, train_hist=None, is_train=True):\n",
    "    \"\"\"以leave one out方式產生 train data, test data\"\"\"\n",
    "    queue = []\n",
    "    data = pd.merge(data[['user_id','anime_id','rating_x']],movie_trans[['anime_id','genre','rating','members']], how=\"left\", on=\"anime_id\")\n",
    "    columns=[\"user_id\", \"anime_id\", \"genre\", \"rating\",\"members\", \"candidate_movie_id\",\"rating_x\"]\n",
    "    for u, df in data.groupby(\"user_id\"):\n",
    "        df = df.sort_values(\"rating_x\", ascending=False)\n",
    "        if not is_train:\n",
    "            user_movies_hist = train_hist.query(\"user_id == {}\".format(u)).anime_id\n",
    "        for i, (_, r) in enumerate(df.iterrows()):\n",
    "            if is_train:\n",
    "                queue.append([int(r.user_id),\n",
    "                              df.anime_id[:i].tolist() + df.anime_id[i + 1:].tolist(),\n",
    "                              r.genre, r.rating, r.members, int(r.anime_id), r.rating_x])\n",
    "            else:\n",
    "                # queue.append([int(r.userId), df.movieId[:i].tolist() + df.movieId[i + 1:].tolist(), r.genres, r.avg_rating, r.year, int(r.movieId), r.rating])\n",
    "                # all_hist = set(user_movies_hist.tolist() + df.movieId[:i].tolist())\n",
    "                all_hist = set(user_movies_hist.tolist())\n",
    "                queue.append([int(r.user_id),\n",
    "                              list(all_hist - set([int(r.anime_id)])),\n",
    "                              r.genre, r.rating, r.members, int(r.anime_id), r.rating_x])\n",
    "    return pd.DataFrame(queue, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trProcessed = loo_preprocess(train, movie_trans)\n",
    "teProcessed = loo_preprocess(test, movie_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>genre</th>\n",
       "      <th>rating</th>\n",
       "      <th>members</th>\n",
       "      <th>candidate_movie_id</th>\n",
       "      <th>rating_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[5, 35, 28, 53, 37, 24, 34, 11, 36, 46, 45, 33...</td>\n",
       "      <td>[1, 15, 18, 41]</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0.123776</td>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[38, 35, 28, 53, 37, 24, 34, 11, 36, 46, 45, 3...</td>\n",
       "      <td>[5, 11, 12]</td>\n",
       "      <td>8.93</td>\n",
       "      <td>0.459852</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[38, 5, 28, 53, 37, 24, 34, 11, 36, 46, 45, 33...</td>\n",
       "      <td>[5, 11, 7, 2]</td>\n",
       "      <td>8.44</td>\n",
       "      <td>0.285233</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[38, 5, 35, 53, 37, 24, 34, 11, 36, 46, 45, 33...</td>\n",
       "      <td>[1, 15, 6, 11, 3, 8]</td>\n",
       "      <td>7.66</td>\n",
       "      <td>0.098711</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[38, 5, 35, 28, 37, 24, 34, 11, 36, 46, 45, 33...</td>\n",
       "      <td>[13, 10, 12]</td>\n",
       "      <td>8.19</td>\n",
       "      <td>0.093929</td>\n",
       "      <td>53</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                           anime_id  \\\n",
       "0        1  [5, 35, 28, 53, 37, 24, 34, 11, 36, 46, 45, 33...   \n",
       "1        1  [38, 35, 28, 53, 37, 24, 34, 11, 36, 46, 45, 3...   \n",
       "2        1  [38, 5, 28, 53, 37, 24, 34, 11, 36, 46, 45, 33...   \n",
       "3        1  [38, 5, 35, 53, 37, 24, 34, 11, 36, 46, 45, 33...   \n",
       "4        1  [38, 5, 35, 28, 37, 24, 34, 11, 36, 46, 45, 33...   \n",
       "\n",
       "                  genre  rating   members  candidate_movie_id  rating_x  \n",
       "0       [1, 15, 18, 41]    8.43  0.123776                  38         9  \n",
       "1           [5, 11, 12]    8.93  0.459852                   5         8  \n",
       "2         [5, 11, 7, 2]    8.44  0.285233                  35         8  \n",
       "3  [1, 15, 6, 11, 3, 8]    7.66  0.098711                  28         7  \n",
       "4          [13, 10, 12]    8.19  0.093929                  53         7  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trProcessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>genre</th>\n",
       "      <th>rating</th>\n",
       "      <th>members</th>\n",
       "      <th>candidate_movie_id</th>\n",
       "      <th>rating_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[50, 55, 26, 40, 52, 42, 41, 31, 47, 1, 57, 39...</td>\n",
       "      <td>[1, 6, 18, 30, 41, 2, 4]</td>\n",
       "      <td>9.10</td>\n",
       "      <td>0.071534</td>\n",
       "      <td>54</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[54, 55, 26, 40, 52, 42, 41, 31, 47, 1, 57, 39...</td>\n",
       "      <td>[49, 47]</td>\n",
       "      <td>8.61</td>\n",
       "      <td>0.189779</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[54, 50, 26, 40, 52, 42, 41, 31, 47, 1, 57, 39...</td>\n",
       "      <td>[0, 21, 10]</td>\n",
       "      <td>7.97</td>\n",
       "      <td>0.030386</td>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[54, 50, 55, 40, 52, 42, 41, 31, 47, 1, 57, 39...</td>\n",
       "      <td>[1, 15, 32, 27, 2, 12]</td>\n",
       "      <td>8.15</td>\n",
       "      <td>0.212930</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[54, 50, 55, 26, 52, 42, 41, 31, 47, 1, 57, 39...</td>\n",
       "      <td>[5, 6, 11, 25, 9, 21]</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.023940</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                           anime_id  \\\n",
       "0        1  [50, 55, 26, 40, 52, 42, 41, 31, 47, 1, 57, 39...   \n",
       "1        1  [54, 55, 26, 40, 52, 42, 41, 31, 47, 1, 57, 39...   \n",
       "2        1  [54, 50, 26, 40, 52, 42, 41, 31, 47, 1, 57, 39...   \n",
       "3        1  [54, 50, 55, 40, 52, 42, 41, 31, 47, 1, 57, 39...   \n",
       "4        1  [54, 50, 55, 26, 52, 42, 41, 31, 47, 1, 57, 39...   \n",
       "\n",
       "                      genre  rating   members  candidate_movie_id  rating_x  \n",
       "0  [1, 6, 18, 30, 41, 2, 4]    9.10  0.071534                  54        10  \n",
       "1                  [49, 47]    8.61  0.189779                  50         9  \n",
       "2               [0, 21, 10]    7.97  0.030386                  55         8  \n",
       "3    [1, 15, 32, 27, 2, 12]    8.15  0.212930                  26         8  \n",
       "4     [5, 6, 11, 25, 9, 21]    7.87  0.023940                  40         8  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teProcessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>anime_id_len</th>\n",
       "      <th>genre</th>\n",
       "      <th>genre_len</th>\n",
       "      <th>rating</th>\n",
       "      <th>members</th>\n",
       "      <th>candidate_movie_id</th>\n",
       "      <th>rating_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9260</td>\n",
       "      <td>[210, 259, 196, 3, 216, 258, 159, 190, 221, 49...</td>\n",
       "      <td>40</td>\n",
       "      <td>[5, 6, 26, 38, 4, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0.021485</td>\n",
       "      <td>279</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1319</td>\n",
       "      <td>[134, 60, 165, 19, 135, 390, 63, 536, 26, 50, ...</td>\n",
       "      <td>109</td>\n",
       "      <td>[5, 6, 11, 3, 4, 12]</td>\n",
       "      <td>6</td>\n",
       "      <td>6.99</td>\n",
       "      <td>0.095968</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8434</td>\n",
       "      <td>[60, 70, 5, 151, 207, 83, 173, 123, 295, 97, 6...</td>\n",
       "      <td>88</td>\n",
       "      <td>[28, 9, 10, 0, 0, 0]</td>\n",
       "      <td>3</td>\n",
       "      <td>8.18</td>\n",
       "      <td>0.037590</td>\n",
       "      <td>181</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44350</td>\n",
       "      <td>[79, 155, 157, 112, 83, 50, 338, 63, 153, 81, ...</td>\n",
       "      <td>14</td>\n",
       "      <td>[1, 3, 8, 2, 0, 0]</td>\n",
       "      <td>4</td>\n",
       "      <td>7.61</td>\n",
       "      <td>0.059914</td>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17367</td>\n",
       "      <td>[97, 113, 83, 460, 670, 329, 436, 60, 106, 82,...</td>\n",
       "      <td>30</td>\n",
       "      <td>[0, 26, 7, 9, 2, 12]</td>\n",
       "      <td>6</td>\n",
       "      <td>8.81</td>\n",
       "      <td>0.236995</td>\n",
       "      <td>153</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                           anime_id  anime_id_len  \\\n",
       "0     9260  [210, 259, 196, 3, 216, 258, 159, 190, 221, 49...            40   \n",
       "1     1319  [134, 60, 165, 19, 135, 390, 63, 536, 26, 50, ...           109   \n",
       "2     8434  [60, 70, 5, 151, 207, 83, 173, 123, 295, 97, 6...            88   \n",
       "3    44350  [79, 155, 157, 112, 83, 50, 338, 63, 153, 81, ...            14   \n",
       "4    17367  [97, 113, 83, 460, 670, 329, 436, 60, 106, 82,...            30   \n",
       "\n",
       "                  genre  genre_len  rating   members  candidate_movie_id  \\\n",
       "0  [5, 6, 26, 38, 4, 0]          5    8.21  0.021485                 279   \n",
       "1  [5, 6, 11, 3, 4, 12]          6    6.99  0.095968                   1   \n",
       "2  [28, 9, 10, 0, 0, 0]          3    8.18  0.037590                 181   \n",
       "3    [1, 3, 8, 2, 0, 0]          4    7.61  0.059914                  41   \n",
       "4  [0, 26, 7, 9, 2, 12]          6    8.81  0.236995                 153   \n",
       "\n",
       "   rating_x  \n",
       "0         9  \n",
       "1         6  \n",
       "2         8  \n",
       "3         9  \n",
       "4         9  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "def do_multi(df, multi_cols):\n",
    "    \"\"\"對於multivalent的欄位, 需要增加一個column去描述該欄位的長度\"\"\"\n",
    "    pad = tf.keras.preprocessing.sequence.pad_sequences\n",
    "    ret = OrderedDict()\n",
    "    for colname, col in df.iteritems():\n",
    "        if colname in multi_cols:\n",
    "            lens = col.map(len)\n",
    "            ret[colname] = list(pad(col, padding=\"post\", maxlen=lens.max()))\n",
    "            ret[colname + \"_len\"] = lens.values\n",
    "        else:\n",
    "            ret[colname] = col.values\n",
    "    return ret\n",
    "def get_minibatches_idx(n, batch_size, shuffle=False):\n",
    "    idx_list = np.arange(n, dtype=\"int32\")\n",
    "    if shuffle:\n",
    "        np.random.shuffle(idx_list)\n",
    "    minibatches = []\n",
    "    minibatch_start = 0\n",
    "    for i in range(n // batch_size):\n",
    "        minibatches.append(idx_list[minibatch_start : minibatch_start + batch_size])\n",
    "        minibatch_start += batch_size\n",
    "\n",
    "    if (minibatch_start != n):\n",
    "        # Make a minibatch out of what is left\n",
    "        minibatches.append(idx_list[minibatch_start:])\n",
    "    return minibatches\n",
    "def dataFn(data, n_batch=128, shuffle=False):\n",
    "    def fn():\n",
    "        dataInner = data.copy()\n",
    "        indices = get_minibatches_idx(len(dataInner), n_batch, shuffle=shuffle)\n",
    "        for ind in indices:\n",
    "            yield do_multi(dataInner.iloc[ind], [\"anime_id\", \"genre\"])\n",
    "    return fn\n",
    "\n",
    "for i, e in enumerate(dataFn(trProcessed, n_batch=5, shuffle=True)(), 1):\n",
    "    # print(e)\n",
    "    break\n",
    "pd.DataFrame(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ModelMfDNN(object):\n",
    "    def __init__(self, n_items, n_genre, dim=32, learning_rate=0.01, reg=0.05, modelDir=\"./model\"):\n",
    "        self.n_items = n_items\n",
    "        self.n_genre = n_genre\n",
    "        self.dim = dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.reg = reg\n",
    "        self.modelDir = modelDir\n",
    "        graph = tf.Graph()\n",
    "        with graph.as_default():\n",
    "            # inputs parts\n",
    "            graph_inputs(self)\n",
    "            # embedding parts\n",
    "            graph_embedding(self)\n",
    "            # deep neural network\n",
    "            graph_dnn(self)\n",
    "            # computation parts\n",
    "            graph_computation(self)\n",
    "            # loss parts\n",
    "            graph_loss(self)\n",
    "            self.saver = tf.train.Saver(tf.global_variables())\n",
    "            self.graph = graph\n",
    "        \n",
    "    def fit(self, sess, trainGen, testGen, reset=False, nEpoch=50):\n",
    "        return fit(self, sess, trainGen, testGen, reset=reset, nEpoch=nEpoch)\n",
    "    \n",
    "    def predict(self, sess, user_queries, items):\n",
    "        self.ckpt(sess, self.modelDir)\n",
    "        return sess.run(self.pred, feed_dict={\n",
    "            self.isTrain: False,\n",
    "            self.user_id: user_queries[\"user_id\"],\n",
    "            self.anime_id: user_queries[\"anime_id\"],\n",
    "            self.anime_id_len: user_queries[\"anime_id_len\"],\n",
    "\n",
    "            self.genre: items[\"genre\"],\n",
    "            self.genre_len: items[\"genre_len\"],\n",
    "            self.rating: items[\"rating\"],\n",
    "            self.members: items[\"members\"],\n",
    "            self.candidate_movie_id: items[\"candidate_movie_id\"]\n",
    "        })\n",
    "    \n",
    "    def resetModel(self, modelDir):\n",
    "        \"\"\"刪除model dir\"\"\"\n",
    "        shutil.rmtree(path=modelDir, ignore_errors=True)\n",
    "        os.makedirs(modelDir)\n",
    "        \n",
    "    def ckpt(self, sess, modelDir):\n",
    "        \"\"\"load latest saved model\"\"\"\n",
    "        latestCkpt = tf.train.latest_checkpoint(modelDir)\n",
    "        if latestCkpt:\n",
    "            self.saver.restore(sess, latestCkpt)\n",
    "        return latestCkpt\n",
    "    \n",
    "    def feed_dict(self, data, mode=\"train\"):\n",
    "        ret = {\n",
    "            self.user_id: data[\"user_id\"],\n",
    "            self.anime_id: data[\"anime_id\"],\n",
    "            self.anime_id_len: data[\"anime_id_len\"],\n",
    "            self.genre: data[\"genre\"],\n",
    "            self.genre_len: data[\"genre_len\"],\n",
    "            self.rating: data[\"rating\"],\n",
    "            self.members: data[\"members\"],\n",
    "            self.candidate_movie_id: data[\"candidate_movie_id\"]\n",
    "        }\n",
    "        ret[self.isTrain] = False\n",
    "        if mode != \"infer\":\n",
    "            ret[self.rating] = data[\"rating\"]\n",
    "            if mode == \"train\":\n",
    "                ret[self.isTrain] = True\n",
    "            elif mode == \"eval\":\n",
    "                pass\n",
    "        return ret\n",
    "\n",
    "    def epochLoss(self, sess, dataGen, tpe=\"rmse\"):\n",
    "        totLoss, totCnt = 0, 0\n",
    "        for data in dataGen():\n",
    "            lossTensor = self.rmse_loss if tpe == \"rmse\" else self.mae_loss\n",
    "            loss = sess.run(lossTensor, feed_dict=self.feed_dict(data, mode=\"eval\"))\n",
    "            totLoss += (loss ** 2 if tpe == \"rmse\" else loss) * len(data[\"anime_id\"])\n",
    "            totCnt += len(data[\"anime_id\"])\n",
    "        return np.sqrt(totLoss / totCnt) if tpe == \"rmse\" else totLoss / totCnt\n",
    "    \n",
    "    def evaluateRMSE(self, sess, dataGen):\n",
    "        \"\"\"計算root mean square error\"\"\"\n",
    "        self.ckpt(sess, self.modelDir)\n",
    "        return self.epochLoss(sess, dataGen, tpe=\"rmse\")\n",
    "\n",
    "    def evaluateMAE(self, sess, dataGen):\n",
    "        \"\"\"計算 mean absolutely error\"\"\"\n",
    "        self.ckpt(sess, self.modelDir)\n",
    "        return self.epochLoss(sess, dataGen, tpe=\"mae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def graph_inputs(self):\n",
    "    # inputs/id_user:0\n",
    "    with tf.variable_scope(\"inputs\"):\n",
    "        self.isTrain = tf.placeholder(tf.bool, None)\n",
    "        # user data\n",
    "        self.user_id = tf.placeholder(tf.int32, [None])\n",
    "        self.anime_id = tf.placeholder(tf.int32, [None, None])\n",
    "        self.anime_id_len = tf.placeholder(tf.int32, [None])\n",
    "        # item data\n",
    "        self.genre = tf.placeholder(tf.int32, [None, None])\n",
    "        self.genre_len = tf.placeholder(tf.int32, [None])\n",
    "        self.rating = tf.placeholder(tf.float32, [None])\n",
    "        self.member = tf.placeholder(tf.float32, [None])\n",
    "        self.candidate_movie_id = tf.placeholder(tf.int32, [None])\n",
    "        self.rating_x = tf.placeholder(tf.float32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def graph_embedding(self):\n",
    "    init_fn = tf.glorot_normal_initializer()\n",
    "    emb_init_fn = tf.glorot_uniform_initializer()\n",
    "    self.b_global = tf.Variable(emb_init_fn(shape=[]), name=\"b_global\")\n",
    "    with tf.variable_scope(\"embedding\"):\n",
    "        self.w_anime_id = tf.Variable(emb_init_fn(shape=[self.n_items, dim]), name=\"w_anime_id\")\n",
    "        self.b_anime_id = tf.Variable(emb_init_fn(shape=[dim]), name=\"b_anime_id\")\n",
    "        self.w_candidate_movie_id = tf.Variable(init_fn(shape=[self.n_items, dim]), name=\"w_candidate_movie_id\")\n",
    "        self.b_candidate_movie_id = tf.Variable(init_fn(shape=[dim + 8 + 2]), name=\"b_candidate_movie_id\")\n",
    "        self.w_genre = tf.Variable(emb_init_fn(shape=[self.n_genre, 8]), name=\"w_genre\")\n",
    "\n",
    "        # query_movie embedding\n",
    "        '''sqrtn aggregation(pooling), X: data, W: weight\n",
    "               X_1*W_1 + X_2*W_2 + ... + X_n*W_n / sqrt(W_1**2 + W_2**2 + ... W_n**2)\n",
    "             = weighted sum of X and normalized W\n",
    "           here data = self.query_emb, weight = query_movie_mask '''\n",
    "        self.query_emb = tf.nn.embedding_lookup(self.w_anime_id, self.anime_id)\n",
    "        query_movie_mask = tf.expand_dims(tf.nn.l2_normalize(tf.to_float(tf.sequence_mask(self.anime_id)), 1), -1)\n",
    "        self.query_emb = tf.reduce_sum(self.query_emb * query_movie_mask, 1)\n",
    "        self.query_bias = tf.matmul(self.query_emb, self.b_anime_id[:, tf.newaxis])\n",
    "\n",
    "        # candidate_movie embedding\n",
    "        self.candidate_emb = tf.nn.embedding_lookup(self.w_candidate_movie_id, self.candidate_movie_id)\n",
    "\n",
    "        # genres embedding\n",
    "        '''sqrtn aggregation(pooling), X: data, W: weight\n",
    "               X_1*W_1 + X_2*W_2 + ... + X_n*W_n / sqrt(W_1**2 + W_2**2 + ... W_n**2)\n",
    "             = weighted sum of X and normalized W\n",
    "           here data = self.genres_emb, weight = genres_mask '''\n",
    "        self.genre_emb = tf.nn.embedding_lookup(self.w_genre, tf.to_int32(self.genre))\n",
    "        genre_mask = tf.expand_dims( tf.nn.l2_normalize(tf.to_float(tf.sequence_mask(self.genre_len)), 1), -1)\n",
    "        self.genre_emb = tf.reduce_sum(self.genre_emb * genre_mask, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def graph_dnn(self):\n",
    "    with tf.variable_scope(\"dnn\"):\n",
    "        init_fn = tf.glorot_uniform_initializer()\n",
    "        # encode [item embedding + item metadata]\n",
    "        self.item_repr = tf.concat([self.candidate_emb, self.genre_emb, self.rating[:, tf.newaxis], self.member[:, tf.newaxis]], 1)\n",
    "        self.candidate_bias = tf.matmul(self.item_repr, self.b_candidate_movie_id[:, tf.newaxis])\n",
    "        \n",
    "        # Do: 目前兩層DNN, 可以試著增加或減少hidden layer, 但是最後要跟query_emb內積, 最後一層維度必須 = dim\n",
    "        # Example:\n",
    "            # self.item_repr = tf.layers.dense(self.item_repr, 64, kernel_initializer=init_fn, activation=tf.nn.relu)\n",
    "            # self.item_repr = tf.layers.dense(self.item_repr, 32, kernel_initializer=init_fn, activation=tf.nn.relu)\n",
    "            # self.item_repr = tf.layers.dense(self.item_repr, self.dim, kernel_initializer=init_fn, activation=tf.nn.relu)\n",
    "\n",
    "        # Do: 若有overfitting後可嘗試dropout\n",
    "        # dp_scale = 0.5\n",
    "        self.item_repr = tf.layers.dense(self.item_repr, self.dim, kernel_initializer=init_fn, activation=tf.nn.relu)\n",
    "        # self.item_repr = tf.layers.dropout(self.item_repr, dp_scale, training=self.isTrain)\n",
    "        self.item_repr = tf.layers.dense(self.item_repr, self.dim, kernel_initializer=init_fn, activation=tf.nn.relu)\n",
    "        # self.item_repr = tf.layers.dropout(self.item_repr, dp_scale, training=self.isTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def graph_computation(self):\n",
    "    with tf.variable_scope(\"computation\"):\n",
    "        infer = tf.reduce_sum(self.query_emb * self.item_repr, 1, keep_dims=True)\n",
    "        infer = tf.add(infer, self.b_global)\n",
    "        infer = tf.add(infer, self.query_bias)\n",
    "        self.infer = tf.add(infer, self.candidate_bias, name=\"infer\")\n",
    "\n",
    "        # one query for all items\n",
    "        self.pred = tf.matmul(self.query_emb, tf.transpose(self.item_repr)) + \\\n",
    "                    tf.reshape(self.candidate_bias, (1, -1)) + self.query_bias + self.b_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def graph_loss(self):\n",
    "    with tf.variable_scope(\"loss\"):\n",
    "        self.loss = tf.losses.mean_squared_error(labels=self.rating_x[:, tf.newaxis], predictions=self.infer)\n",
    "        # for eval\n",
    "        self.rmse_loss = tf.sqrt(self.loss)\n",
    "        self.mae_loss = tf.reduce_mean(tf.abs(self.infer - self.rating_x[:, tf.newaxis]))\n",
    "\n",
    "    with tf.variable_scope(\"train\"):\n",
    "        # Do: 嘗試不同的Optimizer\n",
    "        #self.train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(self.loss)\n",
    "        # self.train_op = tf.train.MomentumOptimizer(learning_rate, 0.9, use_nesterov=True).minimize(self.loss)\n",
    "        # self.train_op = tf.train.AdagradOptimizer(learning_rate).minimize(self.loss)\n",
    "        # self.train_op = tf.train.RMSPropOptimizer(learning_rate).minimize(self.loss)\n",
    "         self.train_op = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit(self, sess, trainGen, testGen, reset=False, nEpoch=50):\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    if reset:\n",
    "        print(\"reset model: clean model dir: {} ...\".format(self.modelDir))\n",
    "        self.resetModel(self.modelDir)\n",
    "    # try: 試著重上次儲存的model再次training\n",
    "    self.ckpt(sess, self.modelDir)\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"%s\\t%s\\t%s\\t%s\" % (\"Epoch\", \"Train Error\", \"Val Error\", \"Elapsed Time\"))\n",
    "    minLoss = 1e7\n",
    "    for ep in range(1, nEpoch + 1):\n",
    "        tr_loss, tr_total = 0, 0\n",
    "        for i, data in enumerate(trainGen(), 1):\n",
    "            loss, _ = sess.run([self.rmse_loss, self.train_op], feed_dict=self.feed_dict(data, mode=\"train\"))\n",
    "            tr_loss += loss ** 2 * len(data[\"anime_id\"])\n",
    "            tr_total += len(data[\"anime_id\"])\n",
    "            print(\"\\rtrain loss: {:.3f}\".format(loss), end=\"\")\n",
    "        if testGen is not None:\n",
    "            epochLoss = self.epochLoss(sess, testGen)\n",
    "\n",
    "        tpl = \"\\r%02d\\t%.3f\\t\\t%.3f\\t\\t%.3f secs\"\n",
    "        if minLoss > epochLoss:\n",
    "            tpl += \", saving ...\"\n",
    "            self.saver.save(sess, os.path.join(self.modelDir, 'model'), global_step=ep)\n",
    "            minLoss = epochLoss\n",
    "\n",
    "        end = time.time()\n",
    "        print(tpl % (ep, np.sqrt(tr_loss / tr_total), epochLoss, end - start))\n",
    "        start = end\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nUsers, nMovies = len(mergedata['user_id'].unique()), len(mergedata['anime_id'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 2 but is rank 3 for 'embedding/MatMul' (op: 'MatMul') with input shapes: [?,?,5], [5,1].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1628\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1629\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape must be rank 2 but is rank 3 for 'embedding/MatMul' (op: 'MatMul') with input shapes: [?,?,5], [5,1].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-13356ebda2f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             modelDir=modelDir)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-5984d697618c>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_items, n_genre, dim, learning_rate, reg, modelDir)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mgraph_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m# embedding parts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mgraph_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0;31m# deep neural network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mgraph_dnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-b305c6af631e>\u001b[0m in \u001b[0;36mgraph_embedding\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mquery_movie_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manime_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_emb\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mquery_movie_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_anime_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# candidate_movie embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   2055\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2056\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[0;32m-> 2057\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   2058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   4558\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   4559\u001b[0m         \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4560\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   4561\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4562\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                 instructions)\n\u001b[0;32m--> 488\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3272\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3273\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3274\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3275\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3276\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1790\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1791\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1792\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape must be rank 2 but is rank 3 for 'embedding/MatMul' (op: 'MatMul') with input shapes: [?,?,5], [5,1]."
     ]
    }
   ],
   "source": [
    "# hyper parameters\n",
    "n_batch = 128\n",
    "# Do: 嘗試不同的learning_rate [0.1, 0.001, 0.0001]\n",
    "learning_rate = 0.001\n",
    "# Do: 嘗試不同的dim [8, 16, 20, 32]\n",
    "dim = 5\n",
    "# 非必要: 改動model dir\n",
    "modelDir = \"./model\"\n",
    "    \n",
    "tf.reset_default_graph()\n",
    "model = ModelMfDNN(\n",
    "            n_items=nMovies,\n",
    "            n_genre=n_genres,\n",
    "            dim=dim,\n",
    "            learning_rate=learning_rate,\n",
    "            modelDir=modelDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
